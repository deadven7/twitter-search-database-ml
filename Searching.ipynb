{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f7891d",
   "metadata": {
    "id": "89f7891d"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Navigate to the parent directory\n",
    "parent = os.path.abspath(os.path.join(cwd, os.pardir))\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.insert(0, parent)\n",
    "\n",
    "# Import the SearchCache class\n",
    "from utils.cache import SearchCache\n",
    "import certifi\n",
    "ca = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bb89bb",
   "metadata": {
    "id": "f9bb89bb"
   },
   "outputs": [],
   "source": [
    "class SearchEngine:\n",
    "    def __init__(self, cache_size=100, cache_ttl=3600):\n",
    "        \"\"\"\n",
    "        Initializes a SearchEngine object with a specified database type and cache settings.\n",
    "\n",
    "        Args:\n",
    "        - cache_size (int): Maximum number of items to store in cache\n",
    "        - cache_ttl (int): Time-to-live (in seconds) for cached items\n",
    "        \"\"\"\n",
    "        # initialize a cache object for the search engine using the SearchCache class\n",
    "        self.cache = SearchCache(cache_size, cache_ttl)\n",
    "        self.db_client = pymongo.MongoClient('mongodb+srv://twitter_user:dbms@cluster0.wkyhu.mongodb.net/?retryWrites=true&w=majority',tlsCAFile=ca)\n",
    "        self.tweets_collection = self.db_client['twitter_db']['tweets_data']\n",
    "        self.db_conn = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"kueen\", host=\"localhost\")\n",
    "        self.users_cursor = self.db_conn.cursor()\n",
    "        self.user_table = 'twitter_users_partitioned'\n",
    "        self.pipeline = [\n",
    "            {\n",
    "                '$project': {\n",
    "                    '_id': 0,\n",
    "                    'tweet_id': 1,\n",
    "                    'user': 1,\n",
    "                    'name': 1,\n",
    "                    'date': 1,\n",
    "                    'text': 1,\n",
    "                    'retweet': {\n",
    "                        '$cond': {\n",
    "                            'if': { '$eq': ['$is_retweet', True] },\n",
    "                            'then': '$retweet',\n",
    "                            'else': None\n",
    "                        }\n",
    "                    },\n",
    "                    'quote': {\n",
    "                        '$cond': {\n",
    "                            'if': { '$eq': ['$is_quote', True] },\n",
    "                            'then': '$quote',\n",
    "                            'else': None\n",
    "                        }\n",
    "                    },\n",
    "                    'retweet_count': {\n",
    "                        '$sum': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$quote', None] },\n",
    "                                {\n",
    "                                    '$cond': [\n",
    "                                        { '$eq': ['$retweet', None] },\n",
    "                                        '$retweet_count',\n",
    "                                        '$retweet.retweet_count'\n",
    "                                    ]\n",
    "                                },\n",
    "                                '$quote.retweet_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    'reply_count': {\n",
    "                        '$sum': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$quote', None] },\n",
    "                                {\n",
    "                                    '$cond': [\n",
    "                                        { '$eq': ['$retweet', None] },\n",
    "                                        '$reply_count',\n",
    "                                        '$retweet.reply_count'\n",
    "                                    ]\n",
    "                                },\n",
    "                                '$quote.reply_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    'favorite_count': {\n",
    "                        '$sum': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$quote', None] },\n",
    "                                {\n",
    "                                    '$cond': [\n",
    "                                        { '$eq': ['$retweet', None] },\n",
    "                                        '$favorite_count',\n",
    "                                        '$retweet.favorite_count'\n",
    "                                    ]\n",
    "                                },\n",
    "                                '$quote.favorite_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    'quote_count': {\n",
    "                        '$sum': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$quote', None] },\n",
    "                                {\n",
    "                                    '$cond': [\n",
    "                                        { '$eq': ['$retweet', None] },\n",
    "                                        '$quote_count',\n",
    "                                        '$retweet.quote_count'\n",
    "                                    ]\n",
    "                                },\n",
    "                                '$quote.quote_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$addFields': {\n",
    "                    'engagement': {\n",
    "                        '$add': [\n",
    "                            {'$multiply': ['$retweet_count', 0.2]},\n",
    "                            {'$multiply': ['$favorite_count', 0.2]},\n",
    "                            {'$multiply': ['$reply_count', 0.3]},\n",
    "                            {'$multiply': ['$quote_count', 0.3]}\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$sort': {\n",
    "                    'engagement': pymongo.DESCENDING,\n",
    "                    'date': pymongo.DESCENDING\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    \n",
    "    def most_popular_users(self, n=10):\n",
    "        \"\"\"\n",
    "        Returns the n most popular Twitter users along with their tweets.\n",
    "\n",
    "        Args:\n",
    "        - n (int): Number of users to return.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of the top n Twitter users, each represented as a dictionary with a 'username' key and a 'tweets' key.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if 'most_popular_users' in self.cache:\n",
    "            print(\"Retrieving 'most popular users' from cache!\")\n",
    "            end_time = time.time()\n",
    "            print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "            return self.cache['most_popular_users']\n",
    "        else:\n",
    "            print(f\"New entry, retrieving 'most popular users' from database!\")\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT * FROM \n",
    "                (SELECT distinct user_id, name, twitter_join_date, location, \n",
    "            verified, followers_count, friends_count, favourites_count,\n",
    "                    dense_rank () over (partition by user_id order by followers_count desc) rnk \n",
    "                FROM \n",
    "                (SELECT * FROM {self.user_table} order by followers_count desc) A\n",
    "                ) B where rnk = 1 \n",
    "                order by followers_count desc limit {n}\"\"\"\n",
    "        \n",
    "        self.users_cursor.execute(query)\n",
    "        results = self.users_cursor.fetchall()\n",
    "\n",
    "        users = []\n",
    "        for row in results:\n",
    "            user = {\n",
    "                'user_id': row[0],\n",
    "                'name': row[1],\n",
    "                'twitter_join_date': row[2],\n",
    "                'location': row[3],\n",
    "                'verified': row[4],\n",
    "                'followers_count': row[5],\n",
    "                'friends_count': row[6],\n",
    "                'favourites_count': row[7],\n",
    "            }\n",
    "            users.append(user)\n",
    "\n",
    "        users = pd.DataFrame(users)\n",
    "        self.cache['most_popular_users'] = users.to_json(orient='records')\n",
    "        self.cache.save_checkpoint()\n",
    "        end_time = time.time()\n",
    "        print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "        \n",
    "        return users\n",
    "    \n",
    "    \n",
    "    def most_engaging_tweets(self, n=10):\n",
    "        \"\"\"\n",
    "        Returns the most engaging n tweets in the database, where engagement is defined as the sum of retweet\n",
    "        count, reply count, quote count, and favorite count.\n",
    "\n",
    "        Args:\n",
    "        - n (int): Number of tweets to return.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of the top n tweets, each represented as a dictionary.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if 'most_engaging_tweets' in self.cache:\n",
    "            print(\"Retrieving 'most engaging tweets' from cache!\")\n",
    "            end_time = time.time()\n",
    "            print(f\"Query took {end_time - start_time:.4f} seconds\\n\")            \n",
    "            return self.cache['most_engaging_tweets']\n",
    "        else:\n",
    "            print(f\"New entry, retrieving 'most engaging tweets' from database!\")\n",
    "\n",
    "        tweets = list(self.tweets_collection.aggregate(self.pipeline + [{'$limit': n}]))\n",
    "        self.cache['most_engaging_tweets'] = tweets\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "        \n",
    "        return tweets\n",
    "\n",
    "    \n",
    "    def most_popular_hashtags(self, n=10):\n",
    "        \"\"\"\n",
    "        Returns the n most popular hashtags in the database.\n",
    "\n",
    "        Args:\n",
    "        - n (int): Number of hashtags to return.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of the top n hashtags, each represented as a dictionary.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if 'most_popular_hashtags' in self.cache:\n",
    "            print(\"Retrieving 'most popular hashtags' from cache!\")\n",
    "            end_time = time.time()\n",
    "            print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "            return self.cache['most_popular_hashtags']\n",
    "        else:\n",
    "            print(f\"New entry, retrieving 'most popular hashtags' from database!\")\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                '$match': {\n",
    "                    '$or': [\n",
    "                        {'media.hashtags': {'$exists': True}},\n",
    "                        {'retweet.media.hashtags': {'$exists': True}},\n",
    "                        {'quote.media.hashtags': {'$exists': True}},\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$project': {\n",
    "                    '_id': 0,\n",
    "                    'hashtags': {\n",
    "                        '$concatArrays': [\n",
    "                            {'$ifNull': ['$media.hashtags', []]},\n",
    "                            {'$ifNull': ['$retweet.media.hashtags', []]},\n",
    "                            {'$ifNull': ['$quote.media.hashtags', []]},\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$unwind': '$hashtags'\n",
    "            },\n",
    "            {\n",
    "                '$group': {\n",
    "                    '_id': '$hashtags',\n",
    "                    'count': {'$sum': 1}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$sort': {\n",
    "                    'count': pymongo.DESCENDING,\n",
    "                    'date': pymongo.DESCENDING\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$limit': n\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        \n",
    "        hashtags = list(self.tweets_collection.aggregate(pipeline))\n",
    "        hashtags = [{x[\"_id\"]: x[\"count\"]} for x in hashtags]\n",
    "        self.cache['most_popular_hashtags'] = hashtags\n",
    "        self.cache.save_checkpoint()\n",
    "        end_time = time.time()\n",
    "        print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "        \n",
    "        return hashtags\n",
    "\n",
    "    \n",
    "    def search_by_date_range(self, start_date_str, end_date_str):\n",
    "        \"\"\"\n",
    "        Returns the top n tweets in the database that were posted within the specified date range.\n",
    "\n",
    "        Args:\n",
    "        - start_date_str (str): Start date of the range in the format 'Fri Apr 24 10:06:09 +0000 2020'\n",
    "        - end_date_str (str): End date of the range in the format 'Fri Apr 24 10:06:09 +0000 2020'\n",
    "        - n (int): Number of tweets to return.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of the top n tweets, each represented as a dictionary.\n",
    "        \"\"\"\n",
    "        start_date = datetime.strptime(start_date_str, '%a %b %d %H:%M:%S %z %Y')\n",
    "        end_date = datetime.strptime(end_date_str, '%a %b %d %H:%M:%S %z %Y')\n",
    "\n",
    "        query = {\n",
    "            'date': {\n",
    "                '$gte': start_date,\n",
    "                '$lte': end_date\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        tweets = self.tweets_collection.find(query)\n",
    "        return tweets\n",
    "\n",
    "\n",
    "    def search_by_username(self, username, n=10):\n",
    "        \"\"\"\n",
    "        Returns the top n users in the database matching the given username.\n",
    "\n",
    "        Args:\n",
    "        - username (str): The username to search for.\n",
    "        - n (int): Number of users to return.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of the top n users, each represented as a dictionary.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if username in self.cache:\n",
    "            print(f\"Retrieving '{username}' from cache!\")\n",
    "            end_time = time.time()\n",
    "            print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "\n",
    "            return self.cache[username]\n",
    "        else:\n",
    "            print(f\"New entry, retrieving '{username}' from database!\")\n",
    "\n",
    "        query = f\"\"\"\n",
    "            SELECT user_id, name, twitter_join_date, location, \n",
    "            verified, followers_count, friends_count, favourites_count\n",
    "            FROM {self.user_table}\n",
    "            WHERE name LIKE '%{username}%'\n",
    "            AND (name, date, followers_count) IN (\n",
    "                SELECT name, MAX(date), MAX(followers_count)\n",
    "                FROM {self.user_table}\n",
    "                WHERE name LIKE '%{username}%'\n",
    "                GROUP BY name, user_id\n",
    "            )\n",
    "            ORDER BY followers_count DESC, verified DESC\n",
    "            LIMIT {n}\n",
    "        \"\"\"\n",
    "\n",
    "        self.users_cursor.execute(query)\n",
    "        results = self.users_cursor.fetchall()\n",
    "\n",
    "        users = []\n",
    "        for row in results:\n",
    "            user = {\n",
    "                'user_id': row[0],\n",
    "                'name': row[1],\n",
    "                'twitter_join_date': row[2],\n",
    "                'location': row[3],\n",
    "                'verified': row[4],\n",
    "                'followers_count': row[5],\n",
    "                'friends_count': row[6],\n",
    "                'favourites_count': row[7],\n",
    "            }\n",
    "            users.append(user)\n",
    "\n",
    "        users = pd.DataFrame(users)\n",
    "        self.cache[username] = users.to_json(orient='records')\n",
    "        self.cache.save_checkpoint()\n",
    "        end_time = time.time()\n",
    "        print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "        \n",
    "        return users\n",
    "    \n",
    "    \n",
    "    def search_by_keyword(self, keyword, start_time, end_time, n=10):\n",
    "        \"\"\"\n",
    "        Returns the top n tweets in the database that contain the given word.\n",
    "\n",
    "        Args:\n",
    "        - keyword (str): The word to search for.\n",
    "        - n (int): Number of tweets to return.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of the top n tweets, each represented as a dictionary.\n",
    "        \"\"\"\n",
    "        st = time.time()\n",
    "        \n",
    "        if keyword in self.cache:\n",
    "            print(f\"Retrieving '{keyword}' from cache!\")\n",
    "            et = time.time()\n",
    "            print(f\"Query took {et - st:.4f} seconds\\n\")\n",
    "\n",
    "            return self.cache[keyword]\n",
    "        else:\n",
    "            print(f\"New entry, retrieving '{keyword}' from database!\")\n",
    "            \n",
    "        start_date = datetime.strptime(start_time, '%a %b %d %H:%M:%S %z %Y')\n",
    "        end_date = datetime.strptime(end_time, '%a %b %d %H:%M:%S %z %Y')\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                '$match': {\n",
    "                    '$text': {\n",
    "                        '$search': keyword\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$limit': n\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        if start_time and end_time:\n",
    "            tweets = list(self.search_by_date_range(start_time, end_time))\n",
    "        else:\n",
    "            tweets = list(self.tweets_collection.aggregate(pipeline + self.pipeline))\n",
    "        self.cache[keyword] = tweets\n",
    "        self.cache.save_checkpoint()\n",
    "        et = time.time()\n",
    "        print(f\"Query took {et - st:.4f} seconds\\n\")\n",
    "        \n",
    "        return tweets\n",
    "    \n",
    "    \n",
    "    def search_by_hashtag(self, hashtag, n=10):\n",
    "        \"\"\"\n",
    "        Returns the top n tweets in the database that contain the given hashtag.\n",
    "\n",
    "        Args:\n",
    "        - hashtag (str): The hashtag to search for.\n",
    "        - n (int): Number of tweets to return.\n",
    "\n",
    "        Returns:\n",
    "        - list: List of the top n tweets, each represented as a dictionary.\n",
    "        \"\"\"\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        if hashtag in self.cache:\n",
    "            print(f\"Retrieving '#{hashtag}' from cache!\")\n",
    "            end_time = time.time()\n",
    "            print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "            return self.cache[hashtag]\n",
    "        else:\n",
    "            print(f\"New entry, retrieving '#{hashtag}' from database!\")\n",
    "\n",
    "        pipeline = [\n",
    "            {\n",
    "                '$match': {\n",
    "                    '$or': [\n",
    "                        {'media.hashtags': {'$in': [hashtag]}},\n",
    "                        {'retweet.media.hashtags': {'$in': [hashtag]}},\n",
    "                        {'quote.media.hashtags': {'$in': [hashtag]}},\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$project': {\n",
    "                    '_id': 0,\n",
    "                    'tweet_id': 1,\n",
    "                    'user': 1,\n",
    "                    'name': 1,\n",
    "                    'date': 1,\n",
    "                    'text': 1,\n",
    "                    'retweet': {\n",
    "                        '$cond': {\n",
    "                            'if': { '$eq': ['$is_retweet', True] },\n",
    "                            'then': '$retweet',\n",
    "                            'else': None\n",
    "                        }\n",
    "                    },\n",
    "                    'quote': {\n",
    "                        '$cond': {\n",
    "                            'if': { '$eq': ['$is_quote', True] },\n",
    "                            'then': '$quote',\n",
    "                            'else': None\n",
    "                        }\n",
    "                    },\n",
    "                    'hashtags': '$media.hashtags',\n",
    "                    'retweet_count': {\n",
    "                        '$sum': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$retweet', None] },\n",
    "                                '$retweet_count',\n",
    "                                '$retweet.retweet_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    'reply_count': {\n",
    "                        '$sum': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$quote', None] },\n",
    "                                {\n",
    "                                    '$cond': [\n",
    "                                        { '$eq': ['$retweet', None] },\n",
    "                                        '$reply_count',\n",
    "                                        '$retweet.reply_count'\n",
    "                                    ]\n",
    "                                },\n",
    "                                '$quote.reply_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    'favorite_count': {\n",
    "                        '$sum': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$retweet', None] },\n",
    "                                '$favorite_count',\n",
    "                                '$retweet.favorite_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                    'quote_count': {\n",
    "                        '$max': {\n",
    "                            '$cond': [\n",
    "                                { '$eq': ['$quote', None] },\n",
    "                                '$quote_count',\n",
    "                                '$quote.quote_count'\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                '$unwind': '$hashtags'\n",
    "            },\n",
    "            {\n",
    "                '$addFields': {\n",
    "                    'engagement': {\n",
    "                        '$toInt': {\n",
    "                            '$add': [\n",
    "                                {'$multiply': ['$retweet_count', 0.2]},\n",
    "                                {'$multiply': ['$favorite_count', 0.2]},\n",
    "                                {'$multiply': ['$reply_count', 0.3]},\n",
    "                                {'$multiply': ['$quote_count', 0.3]}\n",
    "                            ]\n",
    "                        }\n",
    "                    },\n",
    "                }\n",
    "            },\n",
    "\n",
    "            {\n",
    "                '$sort': {\n",
    "                    'engagement': pymongo.DESCENDING,\n",
    "                    'date': pymongo.DESCENDING\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                '$limit': n\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        tweets = list(self.tweets_collection.aggregate(pipeline))\n",
    "        self.cache['#'+hashtag] = tweets\n",
    "        self.cache.save_checkpoint()\n",
    "        end_time = time.time()\n",
    "        print(f\"Query took {end_time - start_time:.4f} seconds\\n\")\n",
    "        \n",
    "        return tweets\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad31ba8",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a788806c",
   "metadata": {
    "id": "a788806c"
   },
   "outputs": [],
   "source": [
    "# create a SearchEngine object with cache size of 50 and cache TTL of 30 seconds\n",
    "search_engine = SearchEngine(cache_size=50, cache_ttl=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02812b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time='Sat Apr 25 14:19:11 +0000 2020'\n",
    "end_time='Sat Apr 25 14:30:00 +0000 2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14ff78",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.most_popular_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.most_popular_users()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ea3e6",
   "metadata": {
    "id": "7d4ea3e6",
    "outputId": "098e64ba-f3fa-4d3d-ab42-e6307fc68a48",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_engine.most_engaging_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce5dbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.cache.get_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67691004",
   "metadata": {
    "id": "67691004"
   },
   "outputs": [],
   "source": [
    "search_engine.most_popular_hashtags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2534bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.most_popular_hashtags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a70a9",
   "metadata": {
    "id": "fa1a70a9",
    "outputId": "c432e2c7-df07-48ac-bc8e-422814f8e796"
   },
   "outputs": [],
   "source": [
    "search_engine.search_by_username(\"Sözcü\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623549d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.search_by_username(\"Sözcü\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f29432",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = search_engine.search_by_keyword(\"Modiji\", start_time, end_time)\n",
    "keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22467e5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "search_engine.search_by_hashtag(\"corona\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d1cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.search_by_username(\"Sözcü\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c42aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.cache.get_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78783d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
